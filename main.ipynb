{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from scipy.sparse import coo_matrix, hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ugly but functional function\n",
    "def create_file(name,mis_labels,agr_labels):\n",
    "    indexes=[x for x in range(5001,6001)]\n",
    "    data={'id':indexes,\n",
    "    'misogynous':mis_labels,\n",
    "    'aggressiveness':agr_labels}\n",
    "    dataframe=pd.DataFrame(data,index=indexes,columns=['id','misogynous','aggressiveness'])\n",
    "    dataframe.to_csv(name,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 1 constained tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAME_train = pd.read_csv('AMI2020_TrainingSet/AMI2020_training_raw.tsv', sep='\\t')\n",
    "DATAFRAME_test=pd.read_csv('test/AMI2020_test_raw.tsv',sep='\\t')\n",
    "DATAFRAME=pd.concat([DATAFRAME_train,DATAFRAME_test])\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "    strip_accents='unicode', analyzer='word', token_pattern=r'\\b[^\\d\\W]+\\b',\n",
    "    ngram_range=(1, 5),use_idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=vectorizer.fit_transform(DATAFRAME['text'])\n",
    "X_train,X_test=X[:5000],X[5000:]\n",
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, max_iter=100000,\n",
    "                         C=3, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         solver = 'liblinear', warm_start=False,\n",
    "                         class_weight=None, random_state=None)\n",
    "\n",
    "model.fit(X_train,DATAFRAME_train['misogynous'])\n",
    "result_mis=model.predict(X_test)\n",
    "model.fit(X_train,DATAFRAME_train['aggressiveness'])\n",
    "result_agr=model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,(mis,agr) in enumerate(zip(result_mis,result_agr)):\n",
    "    if mis==0 and agr==1:\n",
    "        result_agr[i]=0 #Sunt 4 cazuri cand se intampla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_file('MDD.A.r.c.run1',result_mis,result_agr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconstrained Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_embeddings(texts,embeddings):\n",
    "    means = []\n",
    "    dim = len(list(embeddings.values())[0])\n",
    "    for text in texts :\n",
    "        text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "        means.append(np.mean([embeddings[w] if w in embeddings else np.zeros(dim) for w in text], axis=0))\n",
    "    return np.array(means)\n",
    "\n",
    "embeddings_index = {}\n",
    "with open('glove/glove.twitter.27B.200d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAME_train = pd.read_csv('AMI2020_TrainingSet/AMI2020_training_raw.tsv', sep='\\t')\n",
    "DATAFRAME_test=pd.read_csv('test/AMI2020_test_raw.tsv',sep='\\t')\n",
    "DATAFRAME=pd.concat([DATAFRAME_train,DATAFRAME_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=DATAFRAME['text'].values\n",
    "X_train,X_test=get_mean_embeddings(X[:5000],embeddings_index),get_mean_embeddings(X[5000:],embeddings_index)\n",
    "\n",
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, max_iter=100000,\n",
    "                         C=3, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         solver = 'liblinear', warm_start=False,\n",
    "                         class_weight=None, random_state=None)\n",
    "\n",
    "model.fit(X_train,DATAFRAME_train['misogynous'])\n",
    "result_mis=model.predict(X_test)\n",
    "model.fit(X_train,DATAFRAME_train['aggressiveness'])\n",
    "result_agr=model.predict(X_test)\n",
    "\n",
    "for i,(mis,agr) in enumerate(zip(result_mis,result_agr)):\n",
    "    if mis==0 and agr==1:\n",
    "        result_agr[i]=0 #Sunt 4 cazuri cand se intampla\n",
    "\n",
    "create_file('MDD.A.r.u.run2',result_mis,result_agr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconstrained run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAME_train = pd.read_csv('different processed dataframes/normal_processed.tsv', sep='\\t')\n",
    "import it_core_news_lg\n",
    "nlp=it_core_news_lg.load()\n",
    "\n",
    "embeddingurile_train=[]\n",
    "for text in DATAFRAME_train['text'].values:\n",
    "    embeddingurile_train.append(nlp(text).vector)\n",
    "\n",
    "\n",
    "embeddingurile_test=[]\n",
    "DATAFRAME_test=pd.read_csv('test/AMI2020_test_raw.tsv',sep='\\t')\n",
    "for text in DATAFRAME_test['text'].values:\n",
    "    embeddingurile_test.append(nlp(text).vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=DATAFRAME_train['clean'].values\n",
    "X_train,X_test=np.array(embeddingurile_train),np.array(embeddingurile_test)\n",
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, max_iter=100000,\n",
    "                         C=3, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         solver = 'liblinear', warm_start=False,\n",
    "                         class_weight=None, random_state=None)\n",
    "\n",
    "\n",
    "model.fit(X_train,DATAFRAME_train['misogynous'])\n",
    "result_mis=model.predict(X_test)\n",
    "model.fit(X_train,DATAFRAME_train['aggressiveness'])\n",
    "result_agr=model.predict(X_test)\n",
    "\n",
    "\n",
    "for i,(mis,agr) in enumerate(zip(result_mis,result_agr)):\n",
    "    if mis==0 and agr==1:\n",
    "        result_agr[i]=0 \n",
    "        \n",
    "create_file('MDD.A.r.u.run3',result_mis,result_agr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK B RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAME_train_synt = pd.read_csv('AMI2020_TrainingSet/AMI2020_training_synt.tsv', sep='\\t')\n",
    "DATAFRAME_train_raw=pd.read_csv('AMI2020_TrainingSet/AMI2020_training_raw.tsv', sep='\\t')\n",
    "DATAFRAME_train=pd.concat([DATAFRAME_train_raw,DATAFRAME_train_synt],ignore_index=True)\n",
    "\n",
    "DATAFRAME_test_synt=pd.read_csv('test/AMI2020_test_synt.tsv',sep='\\t')\n",
    "DATAFRAME_test_raw=pd.read_csv('test/AMI2020_test_raw.tsv',sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_embeddings(texts,embeddings):\n",
    "    means = []\n",
    "    dim = len(list(embeddings.values())[0])\n",
    "    for text in texts :\n",
    "        text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "        means.append(np.mean([embeddings[w] if w in embeddings else np.zeros(dim) for w in text], axis=0))\n",
    "    return np.array(means)\n",
    "\n",
    "embeddings_index = {}\n",
    "with open('glove/glove.twitter.27B.200d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test_raw,X_test_synt=get_mean_embeddings(DATAFRAME_train['text'],embeddings_index),get_mean_embeddings(DATAFRAME_test_raw['text'],embeddings_index),get_mean_embeddings(DATAFRAME_test_synt['text'],embeddings_index)\n",
    "\n",
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, max_iter=100000,\n",
    "                         C=3, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         solver = 'liblinear', warm_start=False,\n",
    "                         class_weight=None, random_state=None)\n",
    "\n",
    "#Raw test\n",
    "model.fit(X_train,DATAFRAME_train['misogynous'])\n",
    "result_mis=model.predict(X_test_raw)\n",
    "create_file_2('MDD.B.r.u.run2',result_mis,'raw')\n",
    "\n",
    "#Synt test\n",
    "model.fit(X_train,DATAFRAME_train['misogynous'])\n",
    "result_mis=model.predict(X_test_synt)\n",
    "create_file_2('MDD.B.s.u.run2',result_mis,'synt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_2(name,mis_labels,data_type):\n",
    "    if data_type=='raw':\n",
    "        indexes=[x for x in range(5001,6001)]\n",
    "    else:\n",
    "        indexes=[x for x in range (2014,3922)]\n",
    "    data={'id':indexes,\n",
    "    'misogynous':mis_labels}\n",
    "    dataframe=pd.DataFrame(data,index=indexes,columns=['id','misogynous'])\n",
    "    dataframe.to_csv(name,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK B RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAME_train_synt = pd.read_csv('AMI2020_TrainingSet/AMI2020_training_synt.tsv', sep='\\t')\n",
    "DATAFRAME_train_synt['clean']=DATAFRAME_train_synt['text']\n",
    "\n",
    "DATAFRAME_train_raw=pd.read_csv('different processed dataframes/noun_chuncks,processed.tsv', sep='\\t')\n",
    "\n",
    "DATAFRAME_train=pd.concat([DATAFRAME_train_raw,DATAFRAME_train_synt],ignore_index=True)\n",
    "DATAFRAME_train['clean']=DATAFRAME_train['clean'].apply(lambda x:str(x)) #le am pus ghena in tsv\n",
    "\n",
    "DATAFRAME_test_synt=pd.read_csv('test/AMI2020_test_synt.tsv',sep='\\t')\n",
    "DATAFRAME_test_raw=pd.read_csv('test/AMI2020_test_raw.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    fatti te lo ti bocca\n",
       "1           tu semafori la lavavetri il vitalizio ti gola\n",
       "2       amore skype ti i miei parenti un tablet i pare...\n",
       "3       salvo la culona mosca aummaumm putin commesse ...\n",
       "4       gentiloni danno la francia ci sarkosy la culon...\n",
       "                              ...                        \n",
       "7009                  sposa non dovrebbe essere soffocata\n",
       "7010             ragazze non dovrebbero essere massacrate\n",
       "7011                      mogli dovrebbero essere stimate\n",
       "7012                                     moglie terribile\n",
       "7013             signorina non dovrebbe essere massacrata\n",
       "Name: clean, Length: 7014, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAFRAME_train['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=get_mean_embeddings(DATAFRAME_train['clean'].values,embeddings_index)\n",
    "X_test_raw,X_test_synt=get_mean_embeddings(DATAFRAME_test_raw['text'],embeddings_index),get_mean_embeddings(DATAFRAME_test_synt['text'],embeddings_index)\n",
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, max_iter=100000,\n",
    "                         C=3, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         solver = 'liblinear', warm_start=False,\n",
    "                         class_weight=None, random_state=None)\n",
    "\n",
    "\n",
    "#Raw test\n",
    "model.fit(X_train,DATAFRAME_train['misogynous'])\n",
    "result_mis=model.predict(X_test_raw)\n",
    "create_file_2('MDD.B.r.u.run3',result_mis,'raw')\n",
    "\n",
    "#Synt test\n",
    "model.fit(X_train,DATAFRAME_train['misogynous'])\n",
    "result_mis=model.predict(X_test_synt)\n",
    "create_file_2('MDD.B.s.u.run3',result_mis,'synt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
