{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from evaluation_submission import evaluate_task_a,evaluate_task_b\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ugly but functional function\n",
    "def create_file(name,mis_labels,agr_labels):\n",
    "    indexes=[x for x in range(5001,6001)]\n",
    "    data={'id':indexes,\n",
    "    'misogynous':mis_labels,\n",
    "    'aggressiveness':agr_labels}\n",
    "    dataframe=pd.DataFrame(data,index=indexes,columns=['id','misogynous','aggressiveness'])\n",
    "    dataframe.to_csv(name,sep='\\t',index=False)\n",
    "def create_file_2(name,mis_labels,data_type):\n",
    "    if data_type=='raw':\n",
    "        indexes=[x for x in range(5001,6001)]\n",
    "    else:\n",
    "        indexes=[x for x in range (2014,3922)]\n",
    "    data={'id':indexes,\n",
    "    'misogynous':mis_labels}\n",
    "    dataframe=pd.DataFrame(data,index=indexes,columns=['id','misogynous'])\n",
    "    dataframe.to_csv(name,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_embeddings(texts,embeddings):\n",
    "    means = []\n",
    "    dim = len(list(embeddings.values())[0])\n",
    "    for text in texts :\n",
    "        text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "        means.append(np.mean([embeddings[w] if w in embeddings else np.zeros(dim) for w in text], axis=0))\n",
    "    return np.array(means)\n",
    "def get_noun_phrases_embeddings(documents, lang='it_core_news_lg'):\n",
    "    nlp = spacy.load(lang)\n",
    "    phrased = []\n",
    "    for idx, text in enumerate(documents):\n",
    "        doc = nlp(text)\n",
    "        all_vectors = [doc[start:end].vector for start,end,_ in noun_chunks(doc)]\n",
    "        if not all_vectors:\n",
    "            all_vectors = [np.zeros((300,))]\n",
    "        phrases = np.mean(all_vectors, axis=0)\n",
    "        phrased.append(phrases)\n",
    "    return np.array(phrased)\n",
    "\n",
    "def get_spacy_embeddings(documents, lang='it_core_news_lg'):\n",
    "    nlp = spacy.load(lang)\n",
    "    phrased = []\n",
    "    for idx, text in enumerate(documents):\n",
    "        doc = nlp(text)\n",
    "        phrased.append(doc.vector)\n",
    "    return np.array(phrased)\n",
    "def run_cv(classifier, k_fold, data, labels, runs=10):\n",
    "    accuracy_scores = []\n",
    "    f1scores = []\n",
    "    auc_scores = [0]\n",
    "    confusion_matrices = []\n",
    "    min_acc = 100\n",
    "    labels = np.array(labels)\n",
    "    skf = StratifiedKFold(k_fold)\n",
    "    for run in range(0, runs):\n",
    "        cv_splits = skf.split(data, labels)\n",
    "        for train, test in cv_splits:\n",
    "            traindata = data[train]\n",
    "            y_traindata = labels[train]\n",
    "            testdata = data[test]\n",
    "            y_testdata = labels[test]\n",
    "            model = clone(classifier)\n",
    "            model.fit(traindata, y_traindata)\n",
    "            result = model.predict(testdata)\n",
    "            score = accuracy_score(y_testdata, result)\n",
    "            accuracy_scores.append(score)\n",
    "            f1sc = f1_score(y_testdata, result, average='weighted') \n",
    "            f1scores.append(f1sc)\n",
    "            #auc = roc_auc_score(y_testdata, result, average='weighted', multi_class='ovr')\n",
    "            #auc_scores.append(auc)\n",
    "            if f1sc < min_acc:\n",
    "                min_acc = f1sc \n",
    "                split_inidices = (train, test)\n",
    "    print(np.mean(f1scores))\n",
    "    print (\"min cv F1: \", min_acc)   \n",
    "    return (accuracy_scores, f1scores, auc_scores, split_inidices)\n",
    "\n",
    "def real_score_A(predicted_mis,real_mis,predicted_agr,real_agr):\n",
    "    f1sc_m = f1_score(real_mis, predicted_mis, average='macro')\n",
    "    f1sc_a = f1_score(real_agr, predicted_agr, average='macro')  \n",
    "    macro_score = (f1sc_m + f1sc_a) / 2\n",
    "    print(f'macro score: {macro_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, max_iter=100000,\n",
    "                         C=3, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         solver = 'liblinear', warm_start=False,\n",
    "                         class_weight=None, random_state=None)\n",
    "vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "    strip_accents='unicode', analyzer='word', token_pattern=r'\\b[^\\d\\W]+\\b',\n",
    "    ngram_range=(1, 5),use_idf=True)\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "with open('glove/glove.twitter.27B.200d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "embeddings_glove=embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names=['tfidf','english_embeddings','italian_embeddings','tfidf + noun phrases','embeddings + noun phrases']\n",
    "#names=[name+'.tsv' for name in names]\n",
    "\n",
    "DATAFRAME_TRAIN_raw = pd.read_csv('AMI2020_TrainingSet/AMI2020_training_raw.tsv', sep='\\t')\n",
    "DATAFRAME_TRAIN_raw['clean']=DATAFRAME_TRAIN_raw['text']\n",
    "\n",
    "DATAFRAME_TEST_raw=pd.read_csv('test/AMI2020_test_raw_gt.tsv',sep='\\t')\n",
    "DATAFRAME_TEST_raw['clean']=DATAFRAME_TEST_raw['text']\n",
    "\n",
    "DATAFRAME_TRAIN_synt = pd.read_csv('AMI2020_TrainingSet/AMI2020_training_synt.tsv', sep='\\t')\n",
    "DATAFRAME_TRAIN_synt['clean']=DATAFRAME_TRAIN_synt['text']\n",
    "\n",
    "DATAFRAME_TEST_synt=pd.read_csv('test/AMI2020_test_synt_gt.tsv',sep='\\t')\n",
    "DATAFRAME_TEST_synt['clean']=DATAFRAME_TEST_synt['text']\n",
    "\n",
    "\n",
    "DATAFRAME_gold_raw = pd.read_csv('test/AMI2020_test_raw_gt.tsv', sep='\\t')\n",
    "DATAFRAME_gold_synt=pd.read_csv('test/AMI2020_test_synt_gt.tsv',sep='\\t')\n",
    "\n",
    "\n",
    "raw_real_mis,raw_real_agr=DATAFRAME_gold_raw['misogynous'],DATAFRAME_gold_raw['aggressiveness']\n",
    "synt_real_mis=DATAFRAME_gold_synt['misogynous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF A si B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_tfidf_related(model,vectorizer,train_raw,test_raw,train_synt,test_synt,method_name='tfidf'):\n",
    "    #task A\n",
    "    RAW=pd.concat([train_raw,test_raw])\n",
    "    SYNT=pd.concat([train_synt,test_synt])\n",
    "    DATAFRAME=pd.concat([RAW,SYNT])\n",
    "    TRAIN_DATAFRAME=pd.concat([train_raw,train_synt])\n",
    "    TEST_DATAFRAME=pd.concat([test_raw,test_synt])\n",
    "\n",
    "    X=vectorizer.fit_transform(RAW['clean'])\n",
    "\n",
    "    #raw\n",
    "    train_x,test_x=X[:5000],X[5000:]\n",
    "\n",
    "    #misog\n",
    "    model.fit(train_x,train_raw['misogynous'])\n",
    "    result_mis=model.predict(test_x)\n",
    "\n",
    "    #agr\n",
    "    model.fit(train_x,train_raw['aggressiveness'])\n",
    "    result_agr=model.predict(test_x)\n",
    "\n",
    "    for i,(mis,agr) in enumerate(zip(result_mis,result_agr)):\n",
    "        if mis==0 and agr==1:\n",
    "            result_agr[i]=0 #Sunt 4 cazuri cand se intampla\n",
    "    create_file('task A '+method_name+'.tsv',result_mis,result_agr)\n",
    "\n",
    "    print(f'\\ncv misogin for {method_name}')\n",
    "    run_cv(model,10,train_x,train_raw['misogynous'])\n",
    "    print(f'\\ncv agresiv for {method_name}')\n",
    "    run_cv(model,10,train_x,train_raw['aggressiveness'])\n",
    "    print('\\nreal score')\n",
    "    real_score_A(result_mis,raw_real_mis,result_agr,raw_real_mis)\n",
    "    '''\n",
    "    #B\n",
    "    print(DATAFRAME['clean'])\n",
    "    X=vectorizer.fit_transform(DATAFRAME['clean'])\n",
    "    x_train=vectorizer.transform(TRAIN_DATAFRAME['clean'])\n",
    "    x_raw_test=vectorizer.transform(test_raw['clean'])\n",
    "    x_synt_test=vectorizer.transform(test_synt['clean'])\n",
    "    model.fit(x_train,TRAIN_DATAFRAME['misogynous'])\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_raw_test.shape)\n",
    "    result_raw=model.predict(x_raw_test)\n",
    "    create_file_2('task B raw '+method_name+'.tsv',result_raw,'raw')\n",
    "\n",
    "    result_synt=model.predict(x_synt_test)\n",
    "    create_file_2('task B synt '+method_name+'.tsv',result_synt,'synt')\n",
    "\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_embedding_related(model,embeddings,train_raw,test_raw,train_synt,test_synt,method_name='embeddings'):\n",
    "    #task A\n",
    "    RAW=pd.concat([train_raw,test_raw])\n",
    "    SYNT=pd.concat([train_synt,test_synt])\n",
    "    DATAFRAME=pd.concat([RAW,SYNT])\n",
    "    TRAIN_DATAFRAME=pd.concat([train_raw,train_synt])\n",
    "    TEST_DATAFRAME=pd.concat([test_raw,test_synt])\n",
    "    nlp=spacy.load('it_core_news_lg')\n",
    "    if method_name=='glove':\n",
    "        X=get_mean_embeddings(RAW['clean'].values,embeddings)\n",
    "    else:\n",
    "        #presupunand ca daca nu e glove simplu e spacy\n",
    "        embeddingurile_train=[]\n",
    "        for text in train_raw['clean'].values:\n",
    "            embeddingurile_train.append(nlp(text).vector)\n",
    "\n",
    "        embeddingurile_test=[]\n",
    "        for text in test_raw['clean'].values:\n",
    "            embeddingurile_test.append(nlp(text).vector)\n",
    "        X=np.concatenate([embeddingurile_train,embeddingurile_test])    \n",
    "\n",
    "\n",
    "    #raw\n",
    "    train_x,test_x=X[:5000],X[5000:]\n",
    "\n",
    "    #misog\n",
    "    model.fit(train_x,train_raw['misogynous'])\n",
    "    result_mis=model.predict(test_x)\n",
    "\n",
    "    #agr\n",
    "    model.fit(train_x,train_raw['aggressiveness'])\n",
    "    result_agr=model.predict(test_x)\n",
    "\n",
    "    for i,(mis,agr) in enumerate(zip(result_mis,result_agr)):\n",
    "        if mis==0 and agr==1:\n",
    "            result_agr[i]=0 #Sunt 4 cazuri cand se intampla\n",
    "\n",
    "    create_file(method_name+' task A.tsv',result_mis,result_agr)\n",
    "\n",
    "    print(f'\\ncv misogin for{method_name}')\n",
    "    run_cv(model,10,train_x,train_raw['misogynous'])\n",
    "    print(f'\\ncv agresiv for{method_name}')\n",
    "    run_cv(model,10,train_x,train_raw['aggressiveness'])\n",
    "    print('\\nreal score')\n",
    "    real_score_A(result_mis,raw_real_mis,result_agr,raw_real_mis)\n",
    "\n",
    "    '''\n",
    "    #B\n",
    "    X=get_mean_embeddings(DATAFRAME['clean'],embeddings)\n",
    "    x_train=get_mean_embeddings(TRAIN_DATAFRAME['clean'],embeddings)\n",
    "    x_raw_test=get_mean_embeddings(test_raw['clean'],embeddings)\n",
    "    x_synt_test=get_mean_embeddings(test_synt['clean'],embeddings)\n",
    "\n",
    "    model.fit(x_train,TRAIN_DATAFRAME['misogynous'])\n",
    "\n",
    "    result_raw=model.predict(x_raw_test)\n",
    "    create_file_2(method_name+' task B raw.tsv',result_raw,'raw')\n",
    "\n",
    "    result_synt=model.predict(x_synt_test)\n",
    "    create_file_2(method_name+' task B synt.tsv',result_synt,'synt')\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "cv misogin for tfidf simplu\n",
      "0.8827527300244864\n",
      "min cv F1:  0.808\n",
      "\n",
      "cv agresiv for tfidf simplu\n",
      "0.8002388134462832\n",
      "min cv F1:  0.5077334870538501\n",
      "\n",
      "real score\n",
      "macro score: 0.7064953843078551\n",
      "\n",
      "cv misogin forglove\n",
      "0.8183242384063837\n",
      "min cv F1:  0.7622142694232932\n",
      "\n",
      "cv agresiv forglove\n",
      "0.7413811683837378\n",
      "min cv F1:  0.48945024436519086\n",
      "\n",
      "real score\n",
      "macro score: 0.6906001893417045\n",
      "\n",
      "cv misogin forspacy\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-4b5553afb862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresults_tfidf_related\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TRAIN_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TEST_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TRAIN_synt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TEST_synt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tfidf simplu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mresults_embedding_related\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membeddings_glove\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TRAIN_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TEST_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TRAIN_synt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TEST_synt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'glove'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresults_embedding_related\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membeddings_glove\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TRAIN_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TEST_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TRAIN_synt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATAFRAME_TEST_synt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'spacy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-b5fe4498fd7a>\u001b[0m in \u001b[0;36mresults_embedding_related\u001b[1;34m(model, embeddings, train_raw, test_raw, train_synt, test_synt, method_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\ncv misogin for{method_name}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mrun_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'misogynous'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\ncv agresiv for{method_name}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mrun_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aggressiveness'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-84aa55986ba2>\u001b[0m in \u001b[0;36mrun_cv\u001b[1;34m(classifier, k_fold, data, labels, runs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0my_testdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_traindata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_testdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1358\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1361\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m         epsilon, sample_weight)\n\u001b[0m\u001b[0;32m    970\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_tfidf_related(model,vectorizer,DATAFRAME_TRAIN_raw,DATAFRAME_TEST_raw,DATAFRAME_TRAIN_synt,DATAFRAME_TEST_synt,'tfidf simplu')\n",
    "results_embedding_related(model,embeddings_glove,DATAFRAME_TRAIN_raw,DATAFRAME_TEST_raw,DATAFRAME_TRAIN_synt,DATAFRAME_TEST_synt,'glove')\n",
    "results_embedding_related(model,embeddings_glove,DATAFRAME_TRAIN_raw,DATAFRAME_TEST_raw,DATAFRAME_TRAIN_synt,DATAFRAME_TEST_synt,'spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}